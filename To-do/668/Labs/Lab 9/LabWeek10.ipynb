{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SentiSynset('dislocation.n.02'),\n",
       " SentiSynset('breakdown.n.02'),\n",
       " SentiSynset('breakdown.n.03'),\n",
       " SentiSynset('breakdown.n.04')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "list(swn.senti_synsets('breakdown'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function sorted(iterable, /, *, key=None, reverse=False)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp1=list(wn.synsets('breakdown'))[0]\n",
    "tmp1.lemmas()\n",
    "sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('dislocation.n.02'),\n",
       " Synset('breakdown.n.02'),\n",
       " Synset('breakdown.n.03'),\n",
       " Synset('breakdown.n.04')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('breakdown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<breakdown.n.03: PosScore=0.0 NegScore=0.25>\n"
     ]
    }
   ],
   "source": [
    "breakdown3 = swn.senti_synset('breakdown.n.03')\n",
    "print(breakdown3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breakdown3.pos_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breakdown3.neg_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breakdown3.obj_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.help.upenn_tagset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10662"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import sentence_polarity\n",
    "import random\n",
    "sentences = sentence_polarity.sents()\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.corpus.reader.util.ConcatenatedCorpusView"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_polarity.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['simplistic', ',', 'silly', 'and', 'tedious', '.'],\n",
       " [\"it's\",\n",
       "  'so',\n",
       "  'laddish',\n",
       "  'and',\n",
       "  'juvenile',\n",
       "  ',',\n",
       "  'only',\n",
       "  'teenage',\n",
       "  'boys',\n",
       "  'could',\n",
       "  'possibly',\n",
       "  'find',\n",
       "  'it',\n",
       "  'funny',\n",
       "  '.'],\n",
       " ['exploitative',\n",
       "  'and',\n",
       "  'largely',\n",
       "  'devoid',\n",
       "  'of',\n",
       "  'the',\n",
       "  'depth',\n",
       "  'or',\n",
       "  'sophistication',\n",
       "  'that',\n",
       "  'would',\n",
       "  'make',\n",
       "  'watching',\n",
       "  'such',\n",
       "  'a',\n",
       "  'graphic',\n",
       "  'treatment',\n",
       "  'of',\n",
       "  'the',\n",
       "  'crimes',\n",
       "  'bearable',\n",
       "  '.'],\n",
       " ['[garbus]',\n",
       "  'discards',\n",
       "  'the',\n",
       "  'potential',\n",
       "  'for',\n",
       "  'pathological',\n",
       "  'study',\n",
       "  ',',\n",
       "  'exhuming',\n",
       "  'instead',\n",
       "  ',',\n",
       "  'the',\n",
       "  'skewed',\n",
       "  'melodrama',\n",
       "  'of',\n",
       "  'the',\n",
       "  'circumstantial',\n",
       "  'situation',\n",
       "  '.']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sents = sentence_polarity.sents(categories='pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5331"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5331"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_sents = sentence_polarity.sents(categories='neg')\n",
    "len(neg_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['simplistic', ',', 'silly', 'and', 'tedious', '.'], 'neg')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [(sent, cat) for cat in sentence_polarity.categories() \n",
    "            for sent in sentence_polarity.sents(categories=cat)]\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['twenty-three',\n",
       "  'movies',\n",
       "  'into',\n",
       "  'a',\n",
       "  'mostly',\n",
       "  'magnificent',\n",
       "  'directorial',\n",
       "  'career',\n",
       "  ',',\n",
       "  'clint',\n",
       "  \"eastwood's\",\n",
       "  'efficiently',\n",
       "  'minimalist',\n",
       "  'style',\n",
       "  'finally',\n",
       "  'has',\n",
       "  'failed',\n",
       "  'him',\n",
       "  '.',\n",
       "  'big',\n",
       "  'time',\n",
       "  '.'],\n",
       " 'neg')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hard'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words_list = [word for (sent,cat) in documents for word in sent]\n",
    "all_words = nltk.FreqDist(all_words_list)\n",
    "word_items = all_words.most_common(2000)\n",
    "word_features = [word for (word,count) in word_items]\n",
    "word_features[200]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_features(document, word_features):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['twenty-three',\n",
       "  'movies',\n",
       "  'into',\n",
       "  'a',\n",
       "  'mostly',\n",
       "  'magnificent',\n",
       "  'directorial',\n",
       "  'career',\n",
       "  ',',\n",
       "  'clint',\n",
       "  \"eastwood's\",\n",
       "  'efficiently',\n",
       "  'minimalist',\n",
       "  'style',\n",
       "  'finally',\n",
       "  'has',\n",
       "  'failed',\n",
       "  'him',\n",
       "  '.',\n",
       "  'big',\n",
       "  'time',\n",
       "  '.'],\n",
       " 'neg')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresets = [(document_features(d, word_features), c) for (d, c) in documents]\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresets[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "          contains(flat) = True              neg : pos    =     22.2 : 1.0\n",
      "    contains(engrossing) = True              pos : neg    =     20.4 : 1.0\n",
      "     contains(wonderful) = True              pos : neg    =     17.7 : 1.0\n",
      "      contains(mediocre) = True              neg : pos    =     16.9 : 1.0\n",
      "       contains(generic) = True              neg : pos    =     15.6 : 1.0\n",
      "       contains(routine) = True              neg : pos    =     15.6 : 1.0\n",
      "     contains(inventive) = True              pos : neg    =     14.4 : 1.0\n",
      "    contains(unexpected) = True              pos : neg    =     14.4 : 1.0\n",
      "    contains(refreshing) = True              pos : neg    =     13.1 : 1.0\n",
      "  contains(refreshingly) = True              pos : neg    =     13.1 : 1.0\n",
      "        contains(boring) = True              neg : pos    =     12.7 : 1.0\n",
      "          contains(warm) = True              pos : neg    =     12.7 : 1.0\n",
      "      contains(powerful) = True              pos : neg    =     12.5 : 1.0\n",
      "     contains(absorbing) = True              pos : neg    =     12.4 : 1.0\n",
      "            contains(90) = True              neg : pos    =     12.3 : 1.0\n",
      "         contains(stale) = True              neg : pos    =     11.6 : 1.0\n",
      "   contains(mesmerizing) = True              pos : neg    =     11.0 : 1.0\n",
      "      contains(provides) = True              pos : neg    =     11.0 : 1.0\n",
      "     contains(realistic) = True              pos : neg    =     11.0 : 1.0\n",
      "      contains(mindless) = True              neg : pos    =     11.0 : 1.0\n",
      "      contains(captures) = True              pos : neg    =     10.6 : 1.0\n",
      "        contains(dreary) = True              neg : pos    =     10.3 : 1.0\n",
      "        contains(unless) = True              neg : pos    =     10.3 : 1.0\n",
      "          contains(dull) = True              neg : pos    =     10.0 : 1.0\n",
      "         contains(jokes) = True              neg : pos    =      9.8 : 1.0\n",
      "        contains(stupid) = True              neg : pos    =      9.8 : 1.0\n",
      "          contains(ages) = True              pos : neg    =      9.7 : 1.0\n",
      "      contains(chilling) = True              pos : neg    =      9.7 : 1.0\n",
      "         contains(pulls) = True              pos : neg    =      9.7 : 1.0\n",
      "         contains(bears) = True              neg : pos    =      9.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = featuresets[1000:], featuresets[:1000]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "classifier.show_most_informative_features(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLpath = 'subjclueslen1-HLTEMNLP05.tff'\n",
    "SLpath = 'sub.tff'\n",
    "def readSubjectivity(path):\n",
    "    flexicon = open(path, 'r')\n",
    "    # initialize an empty dictionary\n",
    "    sldict = { }\n",
    "    for line in flexicon:\n",
    "        fields = line.split()   # default is to split on whitespace\n",
    "        # split each field on the '=' and keep the second part as the value\n",
    "        strength = fields[0].split(\"=\")[1]\n",
    "        word = fields[2].split(\"=\")[1]\n",
    "        posTag = fields[3].split(\"=\")[1]\n",
    "        stemmed = fields[4].split(\"=\")[1]\n",
    "        polarity = fields[5].split(\"=\")[1]\n",
    "        if (stemmed == 'y'):\n",
    "            isStemmed = True\n",
    "        else:\n",
    "            isStemmed = False\n",
    "        # put a dictionary entry with the word as the keyword\n",
    "        #     and a list of the other values\n",
    "        sldict[word] = [strength, posTag, isStemmed, polarity]\n",
    "    return sldict\n",
    "SL = readSubjectivity(SLpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6885"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SL.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['strongsubj', 'adj', False, 'neutral']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SL['absolute']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['strongsubj', 'adj', False, 'negative']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SL['shabby']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SL_features(document, word_features, SL):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    # count variables for the 4 classes of subjectivity\n",
    "    weakPos = 0\n",
    "    strongPos = 0\n",
    "    weakNeg = 0\n",
    "    strongNeg = 0\n",
    "    for word in document_words:\n",
    "        if word in SL:\n",
    "            strength, posTag, isStemmed, polarity = SL[word]\n",
    "            if strength == 'weaksubj' and polarity == 'positive':\n",
    "                weakPos += 1\n",
    "            if strength == 'strongsubj' and polarity == 'positive':\n",
    "                strongPos += 1\n",
    "            if strength == 'weaksubj' and polarity == 'negative':\n",
    "                weakNeg += 1\n",
    "            if strength == 'strongsubj' and polarity == 'negative':\n",
    "                strongNeg += 1\n",
    "            features['positivecount'] = weakPos + (2 * strongPos)\n",
    "            features['negativecount'] = weakNeg + (2 * strongNeg)      \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "SL_featuresets = [(SL_features(d, word_features, SL), c) for (d, c) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SL_featuresets[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SL_featuresets[0][0]['positivecount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SL_featuresets[0][0]['contains(parts)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.761"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, test_set = SL_featuresets[1000:], SL_featuresets[:1000]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['there', 'is', 'a', 'difference', 'between', 'movies', 'with', 'the', 'courage', 'to', 'go', 'over', 'the', 'top', 'and', 'movies', 'that', \"don't\", 'care', 'about', 'being', 'stupid']\n",
      "['a', 'farce', 'of', 'a', 'parody', 'of', 'a', 'comedy', 'of', 'a', 'premise', ',', 'it', \"isn't\", 'a', 'comparison', 'to', 'reality', 'so', 'much', 'as', 'it', 'is', 'a', 'commentary', 'about', 'our', 'knowledge', 'of', 'films', '.']\n",
      "['i', \"didn't\", 'laugh', '.', 'i', \"didn't\", 'smile', '.', 'i', 'survived', '.']\n",
      "['i', \"didn't\", 'laugh', '.', 'i', \"didn't\", 'smile', '.', 'i', 'survived', '.']\n",
      "['most', 'of', 'the', 'problems', 'with', 'the', 'film', \"don't\", 'derive', 'from', 'the', 'screenplay', ',', 'but', 'rather', 'the', 'mediocre', 'performances', 'by', 'most', 'of', 'the', 'actors', 'involved']\n",
      "['the', 'lack', 'of', 'naturalness', 'makes', 'everything', 'seem', 'self-consciously', 'poetic', 'and', 'forced', '.', '.', '.', \"it's\", 'a', 'pity', 'that', \"[nelson's]\", 'achievement', \"doesn't\", 'match', 'his', 'ambition', '.']\n"
     ]
    }
   ],
   "source": [
    "for sent in list(sentences)[:50]:\n",
    "   for word in sent:\n",
    "     if (word.endswith(\"n't\")):\n",
    "       print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "negationwords = ['no', 'not', 'never', 'none', 'nowhere', 'nothing', 'noone', 'rather', 'hardly', 'scarcely', 'rarely', 'seldom', 'neither', 'nor']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NOT_features(document, word_features, negationwords):\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = False\n",
    "        features['contains(NOT{})'.format(word)] = False\n",
    "    # go through document words in order\n",
    "    for i in range(0, len(document)):\n",
    "        word = document[i]\n",
    "        if ((i + 1) < len(document)) and ((word in negationwords) or (word.endswith(\"n't\"))):\n",
    "            i += 1\n",
    "            features['contains(NOT{})'.format(document[i])] = (document[i] in word_features)\n",
    "        else:\n",
    "            features['contains({})'.format(word)] = (word in word_features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NOT_featuresets = [(NOT_features(d, word_features, negationwords), c) for (d, c) in documents]\n",
    "NOT_featuresets[0][0]['contains(NOTlike)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NOT_featuresets[0][0]['contains(always)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.768"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, test_set = NOT_featuresets[1000:], NOT_featuresets[:1000]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "          contains(flat) = True              neg : pos    =     22.2 : 1.0\n",
      "    contains(engrossing) = True              pos : neg    =     20.4 : 1.0\n",
      "     contains(wonderful) = True              pos : neg    =     17.7 : 1.0\n",
      "      contains(mediocre) = True              neg : pos    =     16.9 : 1.0\n",
      "       contains(generic) = True              neg : pos    =     15.6 : 1.0\n",
      "       contains(routine) = True              neg : pos    =     15.6 : 1.0\n",
      "     contains(inventive) = True              pos : neg    =     14.4 : 1.0\n",
      "    contains(unexpected) = True              pos : neg    =     14.4 : 1.0\n",
      "    contains(refreshing) = True              pos : neg    =     13.1 : 1.0\n",
      "  contains(refreshingly) = True              pos : neg    =     13.1 : 1.0\n",
      "        contains(boring) = True              neg : pos    =     12.7 : 1.0\n",
      "          contains(warm) = True              pos : neg    =     12.7 : 1.0\n",
      "      contains(powerful) = True              pos : neg    =     12.5 : 1.0\n",
      "     contains(absorbing) = True              pos : neg    =     12.4 : 1.0\n",
      "            contains(90) = True              neg : pos    =     12.3 : 1.0\n",
      "         contains(stale) = True              neg : pos    =     11.6 : 1.0\n",
      "   contains(mesmerizing) = True              pos : neg    =     11.0 : 1.0\n",
      "      contains(provides) = True              pos : neg    =     11.0 : 1.0\n",
      "     contains(realistic) = True              pos : neg    =     11.0 : 1.0\n",
      "     contains(NOTenough) = True              neg : pos    =     11.0 : 1.0\n",
      "      contains(mindless) = True              neg : pos    =     11.0 : 1.0\n",
      "      contains(captures) = True              pos : neg    =     10.6 : 1.0\n",
      "        contains(dreary) = True              neg : pos    =     10.3 : 1.0\n",
      "        contains(unless) = True              neg : pos    =     10.3 : 1.0\n",
      "          contains(dull) = True              neg : pos    =     10.0 : 1.0\n",
      "         contains(jokes) = True              neg : pos    =      9.8 : 1.0\n",
      "        contains(stupid) = True              neg : pos    =      9.8 : 1.0\n",
      "          contains(ages) = True              pos : neg    =      9.7 : 1.0\n",
      "      contains(chilling) = True              pos : neg    =      9.7 : 1.0\n",
      "         contains(pulls) = True              pos : neg    =      9.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}