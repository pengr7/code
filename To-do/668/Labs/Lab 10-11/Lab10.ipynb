{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classify part of speech based on sentence context\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "\n",
    "# define features for the \"i\"th word in the sentence, including three types of suffix \n",
    "#     and one pre-word\n",
    "# the pos features function takes the sentence of untagged words and the index of a word i\n",
    "#   it creates features for word i, including the previous word i-1\n",
    "def pos_features(sentence, i):    \n",
    "    features = {\"suffix(1)\": sentence[i][-1:],\n",
    "\t\t    \"suffix(2)\": sentence[i][-2:],\n",
    "\t\t    \"suffix(3)\": sentence[i][-3:]}\n",
    "    if i == 0:\n",
    "        features[\"prev-word\"] = \"<START>\"\n",
    "    else:\n",
    "        features[\"prev-word\"] = sentence[i-1]\n",
    "    return features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'investigation'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at features of a specific word in a specific sentence\n",
    "# first sentence of brown corpus\n",
    "sentence0 = brown.sents()[0]\n",
    "print(sentence0)\n",
    "# word 8 of sentence 0\n",
    "sentence0[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prev-word': 'an', 'suffix(1)': 'n', 'suffix(2)': 'on', 'suffix(3)': 'ion'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_features(sentence0, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'),\n",
       " ('Fulton', 'NP-TL'),\n",
       " ('County', 'NN-TL'),\n",
       " ('Grand', 'JJ-TL'),\n",
       " ('Jury', 'NN-TL'),\n",
       " ('said', 'VBD'),\n",
       " ('Friday', 'NR'),\n",
       " ('an', 'AT'),\n",
       " ('investigation', 'NN'),\n",
       " ('of', 'IN'),\n",
       " (\"Atlanta's\", 'NP$'),\n",
       " ('recent', 'JJ'),\n",
       " ('primary', 'NN'),\n",
       " ('election', 'NN'),\n",
       " ('produced', 'VBD'),\n",
       " ('``', '``'),\n",
       " ('no', 'AT'),\n",
       " ('evidence', 'NN'),\n",
       " (\"''\", \"''\"),\n",
       " ('that', 'CS'),\n",
       " ('any', 'DTI'),\n",
       " ('irregularities', 'NNS'),\n",
       " ('took', 'VBD'),\n",
       " ('place', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sents = brown.tagged_sents(categories='news')\n",
    "tag_sent0 = tagged_sents[0]\n",
    "tag_sent0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 The AT\n",
      "1 Fulton NP-TL\n",
      "2 County NN-TL\n",
      "3 Grand JJ-TL\n",
      "4 Jury NN-TL\n",
      "5 said VBD\n",
      "6 Friday NR\n",
      "7 an AT\n",
      "8 investigation NN\n",
      "9 of IN\n",
      "10 Atlanta's NP$\n",
      "11 recent JJ\n",
      "12 primary NN\n",
      "13 election NN\n",
      "14 produced VBD\n",
      "15 `` ``\n",
      "16 no AT\n",
      "17 evidence NN\n",
      "18 '' ''\n",
      "19 that CS\n",
      "20 any DTI\n",
      "21 irregularities NNS\n",
      "22 took VBD\n",
      "23 place NN\n",
      "24 . .\n"
     ]
    }
   ],
   "source": [
    "nltk.tag.untag(tag_sent0)\n",
    "for i,(word,tag) in enumerate(tag_sent0):\n",
    "    print (i, word, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'suffix(1)': 'e', 'suffix(2)': 'he', 'suffix(3)': 'The', 'prev-word': '<START>'}, 'AT')\n",
      "({'suffix(1)': 'n', 'suffix(2)': 'on', 'suffix(3)': 'ton', 'prev-word': 'The'}, 'NP-TL')\n",
      "({'suffix(1)': 'y', 'suffix(2)': 'ty', 'suffix(3)': 'nty', 'prev-word': 'Fulton'}, 'NN-TL')\n",
      "({'suffix(1)': 'd', 'suffix(2)': 'nd', 'suffix(3)': 'and', 'prev-word': 'County'}, 'JJ-TL')\n",
      "({'suffix(1)': 'y', 'suffix(2)': 'ry', 'suffix(3)': 'ury', 'prev-word': 'Grand'}, 'NN-TL')\n",
      "({'suffix(1)': 'd', 'suffix(2)': 'id', 'suffix(3)': 'aid', 'prev-word': 'Jury'}, 'VBD')\n",
      "({'suffix(1)': 'y', 'suffix(2)': 'ay', 'suffix(3)': 'day', 'prev-word': 'said'}, 'NR')\n",
      "({'suffix(1)': 'n', 'suffix(2)': 'an', 'suffix(3)': 'an', 'prev-word': 'Friday'}, 'AT')\n",
      "({'suffix(1)': 'n', 'suffix(2)': 'on', 'suffix(3)': 'ion', 'prev-word': 'an'}, 'NN')\n",
      "({'suffix(1)': 'f', 'suffix(2)': 'of', 'suffix(3)': 'of', 'prev-word': 'investigation'}, 'IN')\n"
     ]
    }
   ],
   "source": [
    "featuresets = []\n",
    "for tagged_sent in tagged_sents:\n",
    "\tuntagged_sent = nltk.tag.untag(tagged_sent)\n",
    "\tfor i, (word, tag) in enumerate(tagged_sent):\n",
    "\t\tfeaturesets.append( (pos_features(untagged_sent, i), tag) )\n",
    "\n",
    "# look at the feature sets of the first 10 words\n",
    "for f in featuresets[:10]:\n",
    "\tprint (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10055"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = int(len(featuresets) * 0.1)\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "len(train_set)\n",
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7891596220785678"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "# evaluate the accuracy (this will take a little while)\n",
    "nltk.classify.accuracy(classifier, test_set)\n",
    "# the result should be 0.78915962207856782, which is reasonable for features without the previous tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', 'START']\n",
      "['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov', '.', '29', '.']\n",
      "['Mr', '.', 'Vinken', 'is', 'chairman', 'of', 'Elsevier', 'N', '.', 'V', '.,', 'the', 'Dutch', 'publishing', 'group', '.']\n",
      "['.', 'START']\n",
      "['Rudolph', 'Agnew', ',', '55', 'years', 'old', 'and', 'former', 'chairman', 'of', 'Consolidated', 'Gold', 'Fields', 'PLC', ',', 'was', 'named', 'a', 'nonexecutive', 'director', 'of', 'this', 'British', 'industrial', 'conglomerate', '.']\n",
      "['.', 'START']\n",
      "['A', 'form', 'of', 'asbestos', 'once', 'used', 'to', 'make', 'Kent', 'cigarette', 'filters', 'has', 'caused', 'a', 'high', 'percentage', 'of', 'cancer', 'deaths', 'among', 'a', 'group', 'of', 'workers', 'exposed', 'to', 'it', 'more', 'than', '30', 'years', 'ago', ',', 'researchers', 'reported', '.']\n",
      "['The', 'asbestos', 'fiber', ',', 'crocidolite', ',', 'is', 'unusually', 'resilient', 'once', 'it', 'enters', 'the', 'lungs', ',', 'with', 'even', 'brief', 'exposures', 'to', 'it', 'causing', 'symptoms', 'that', 'show', 'up', 'decades', 'later', ',', 'researchers', 'said', '.']\n",
      "['Lorillard', 'Inc', '.,', 'the', 'unit', 'of', 'New', 'York', '-', 'based', 'Loews', 'Corp', '.', 'that', 'makes', 'Kent', 'cigarettes', ',', 'stopped', 'using', 'crocidolite', 'in', 'its', 'Micronite', 'cigarette', 'filters', 'in', '1956', '.']\n",
      "['Although', 'preliminary', 'findings', 'were', 'reported', 'more', 'than', 'a', 'year', 'ago', ',', 'the', 'latest', 'results', 'appear', 'in', 'today', \"'\", 's', 'New', 'England', 'Journal', 'of', 'Medicine', ',', 'a', 'forum', 'likely', 'to', 'bring', 'new', 'attention', 'to', 'the', 'problem', '.']\n"
     ]
    }
   ],
   "source": [
    "### sentence segmentation\n",
    "sents = nltk.corpus.treebank_raw.sents()\n",
    "len(sents)\n",
    "for sent in sents[:10]:\n",
    "    print (sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize an empty token list, an empty boundaries set and offset as the integer 0\n",
    "tokens = [ ]\n",
    "boundaries = set()\n",
    "offset = 0\n",
    "# make a list of tokens with sentence boundaries\n",
    "#   the offset is set to the index of a sentence boundary\n",
    "for sent in nltk.corpus.treebank_raw.sents():\n",
    "      tokens.extend(sent)\n",
    "      offset += len(sent)\n",
    "      boundaries.add(offset - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', 'START', 'Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov', '.', '29', '.', 'Mr', '.', 'Vinken', 'is', 'chairman', 'of', 'Elsevier', 'N', '.', 'V', '.,', 'the', 'Dutch', 'publishing', 'group', '.', '.', 'START', 'Rudolph']\n",
      "4193\n",
      "0 . \t False\n",
      "1 START \t True\n",
      "2 Pierre \t False\n",
      "3 Vinken \t False\n",
      "4 , \t False\n",
      "5 61 \t False\n",
      "6 years \t False\n",
      "7 old \t False\n",
      "8 , \t False\n",
      "9 will \t False\n",
      "10 join \t False\n",
      "11 the \t False\n",
      "12 board \t False\n",
      "13 as \t False\n",
      "14 a \t False\n",
      "15 nonexecutive \t False\n",
      "16 director \t False\n",
      "17 Nov \t False\n",
      "18 . \t False\n",
      "19 29 \t False\n",
      "20 . \t True\n",
      "21 Mr \t False\n",
      "22 . \t False\n",
      "23 Vinken \t False\n",
      "24 is \t False\n",
      "25 chairman \t False\n",
      "26 of \t False\n",
      "27 Elsevier \t False\n",
      "28 N \t False\n",
      "29 . \t False\n",
      "30 V \t False\n",
      "31 ., \t False\n",
      "32 the \t False\n",
      "33 Dutch \t False\n",
      "34 publishing \t False\n",
      "35 group \t False\n",
      "36 . \t True\n",
      "37 . \t False\n",
      "38 START \t True\n",
      "39 Rudolph \t False\n"
     ]
    }
   ],
   "source": [
    "# look at tokens and boundaries\n",
    "print(tokens[:40])\n",
    "print(len(boundaries))\n",
    "0 in boundaries\n",
    "1 in boundaries\n",
    "19 in boundaries\n",
    "20 in boundaries\n",
    "for num, tok in enumerate(tokens[:40]):\n",
    "     print (num, tok, '\\t', num in boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature extraction function\n",
    "# token is a list of words and we get the features of the token at offset i\n",
    "def punct_features(tokens, i):\n",
    "    return {'next-word-capitalized': tokens[i+1][0].isupper(),\n",
    "        'prevword': tokens[i-1].lower(),\n",
    "        'punct': tokens[i],\n",
    "        'prev-word-is-one-char': len(tokens[i-1]) == 1}\n",
    "\n",
    "# feature dictionary for the period at index 20\n",
    "tokens[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'next-word-capitalized': True,\n",
       " 'prev-word-is-one-char': False,\n",
       " 'prevword': '29',\n",
       " 'punct': '.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punct_features(tokens,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'next-word-capitalized': False, 'prevword': 'nov', 'punct': '.', 'prev-word-is-one-char': False}, False)\n",
      "({'next-word-capitalized': True, 'prevword': '29', 'punct': '.', 'prev-word-is-one-char': False}, True)\n",
      "({'next-word-capitalized': True, 'prevword': 'mr', 'punct': '.', 'prev-word-is-one-char': False}, False)\n",
      "({'next-word-capitalized': True, 'prevword': 'n', 'punct': '.', 'prev-word-is-one-char': True}, False)\n",
      "({'next-word-capitalized': False, 'prevword': 'group', 'punct': '.', 'prev-word-is-one-char': False}, True)\n",
      "({'next-word-capitalized': True, 'prevword': '.', 'punct': '.', 'prev-word-is-one-char': True}, False)\n",
      "({'next-word-capitalized': False, 'prevword': 'conglomerate', 'punct': '.', 'prev-word-is-one-char': False}, True)\n",
      "({'next-word-capitalized': True, 'prevword': '.', 'punct': '.', 'prev-word-is-one-char': True}, False)\n",
      "({'next-word-capitalized': True, 'prevword': 'reported', 'punct': '.', 'prev-word-is-one-char': False}, True)\n",
      "({'next-word-capitalized': True, 'prevword': 'said', 'punct': '.', 'prev-word-is-one-char': False}, True)\n"
     ]
    }
   ],
   "source": [
    "# Define featuresets of all candidate punctuation\n",
    "Sfeaturesets = [(punct_features(tokens, i), (i in boundaries))\n",
    "      for i in range(1, len(tokens) - 1)\n",
    "      if tokens[i] in '.?!']\n",
    "\n",
    "# look at the feature sets of the first 10 punctuation symbols\n",
    "for sf in Sfeaturesets[:10]:\n",
    "\tprint (sf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "594"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# separate into training and test sets and build classifier\n",
    "size = int(len(Sfeaturesets) * 0.1)\n",
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.936026936026936"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Strain_set, Stest_set = Sfeaturesets[size:], Sfeaturesets[:size]\n",
    "Sclassifier = nltk.NaiveBayesClassifier.train(Strain_set)\n",
    "nltk.classify.accuracy(Sclassifier, Stest_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the . after Nov\n",
    "Sclassifier.classify(punct_features(tokens, 18))\n",
    "# this is the . after 29, which should be true!\n",
    "Sclassifier.classify(punct_features(tokens, 20))\n",
    "# this is the . after group\n",
    "Sclassifier.classify(punct_features(tokens, 36))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# define function to use the trained classifier to label sentences\n",
    "def segment_sentences(words):\n",
    "      start = 0\n",
    "      sents = []\n",
    "      for i, word in enumerate(words):\n",
    "          if word in '.?!' and i < len(words) - 1 and Sclassifier.classify(punct_features(words, i)) == True:\n",
    "              sents.append(words[start:i+1])\n",
    "              start = i+1\n",
    "      if start < len(words):\n",
    "          sents.append(words[start:])\n",
    "      return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101797\n",
      "['.']\n",
      "['START', 'Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov', '.', '29', '.', 'Mr', '.', 'Vinken', 'is', 'chairman', 'of', 'Elsevier', 'N', '.', 'V', '.,', 'the', 'Dutch', 'publishing', 'group', '.']\n",
      "['.', 'START', 'Rudolph', 'Agnew', ',', '55', 'years', 'old', 'and', 'former', 'chairman', 'of', 'Consolidated', 'Gold', 'Fields', 'PLC', ',', 'was', 'named', 'a', 'nonexecutive', 'director', 'of', 'this', 'British', 'industrial', 'conglomerate', '.', '.', 'START', 'A', 'form', 'of', 'asbestos', 'once', 'used', 'to', 'make', 'Kent', 'cigarette', 'filters', 'has', 'caused', 'a', 'high', 'percentage', 'of', 'cancer', 'deaths', 'among', 'a', 'group', 'of', 'workers', 'exposed', 'to', 'it', 'more', 'than', '30', 'years', 'ago', ',', 'researchers', 'reported', '.']\n",
      "['The', 'asbestos', 'fiber', ',', 'crocidolite', ',', 'is', 'unusually', 'resilient', 'once', 'it', 'enters', 'the', 'lungs', ',', 'with', 'even', 'brief', 'exposures', 'to', 'it', 'causing', 'symptoms', 'that', 'show', 'up', 'decades', 'later', ',', 'researchers', 'said', '.']\n",
      "['Lorillard', 'Inc', '.,', 'the', 'unit', 'of', 'New', 'York', '-', 'based', 'Loews', 'Corp', '.', 'that', 'makes', 'Kent', 'cigarettes', ',', 'stopped', 'using', 'crocidolite', 'in', 'its', 'Micronite', 'cigarette', 'filters', 'in', '1956', '.']\n",
      "['Although', 'preliminary', 'findings', 'were', 'reported', 'more', 'than', 'a', 'year', 'ago', ',', 'the', 'latest', 'results', 'appear', 'in', 'today', \"'\", 's', 'New', 'England', 'Journal', 'of', 'Medicine', ',', 'a', 'forum', 'likely', 'to', 'bring', 'new', 'attention', 'to', 'the', 'problem', '.']\n",
      "['A', 'Lorillard', 'spokewoman', 'said', ',', '\"', 'This', 'is', 'an', 'old', 'story', '.']\n",
      "['We', \"'\", 're', 'talking', 'about', 'years', 'ago', 'before', 'anyone', 'heard', 'of', 'asbestos', 'having', 'any', 'questionable', 'properties', '.']\n",
      "['There', 'is', 'no', 'asbestos', 'in', 'our', 'products', 'now', '.\"', 'Neither', 'Lorillard', 'nor', 'the', 'researchers', 'who', 'studied', 'the', 'workers', 'were', 'aware', 'of', 'any', 'research', 'on', 'smokers', 'of', 'the', 'Kent', 'cigarettes', '.']\n",
      "['\"', 'We', 'have', 'no', 'useful', 'information', 'on', 'whether', 'users', 'are', 'at', 'risk', ',\"', 'said', 'James', 'A', '.', 'Talcott', 'of', 'Boston', \"'\", 's', 'Dana', '-', 'Farber', 'Cancer', 'Institute', '.']\n",
      "['Dr', '.', 'Talcott', 'led', 'a', 'team', 'of', 'researchers', 'from', 'the', 'National', 'Cancer', 'Institute', 'and', 'the', 'medical', 'schools', 'of', 'Harvard', 'University', 'and', 'Boston', 'University', '.']\n",
      "['The', 'Lorillard', 'spokeswoman', 'said', 'asbestos', 'was', 'used', 'in', '\"', 'very', 'modest', 'amounts', '\"', 'in', 'making', 'paper', 'for', 'the', 'filters', 'in', 'the', 'early', '1950s', 'and', 'replaced', 'with', 'a', 'different', 'type', 'of', 'filter', 'in', '1956', '.']\n",
      "['From', '1953', 'to', '1955', ',', '9', '.', '8', 'billion', 'Kent', 'cigarettes', 'with', 'the', 'filters', 'were', 'sold', ',', 'the', 'company', 'said', '.']\n",
      "['Among', '33', 'men', 'who', 'worked', 'closely', 'with', 'the', 'substance', ',', '28', 'have', 'died', '--', 'more', 'than', 'three', 'times', 'the', 'expected', 'number', '.']\n",
      "['Four', 'of', 'the', 'five', 'surviving', 'workers', 'have', 'asbestos', '-', 'related', 'diseases', ',', 'including', 'three', 'with', 'recently', 'diagnosed', 'cancer', '.']\n",
      "['The', 'total', 'of', '18', 'deaths', 'from', 'malignant', 'mesothelioma', ',', 'lung', 'cancer', 'and', 'asbestosis', 'was', 'far', 'higher', 'than', 'expected', ',', 'the', 'researchers', 'said', '.']\n",
      "['\"', 'The', 'morbidity', 'rate', 'is', 'a', 'striking', 'finding', 'among', 'those', 'of', 'us', 'who', 'study', 'asbestos', '-', 'related', 'diseases', ',\"', 'said', 'Dr', '.', 'Talcott', '.']\n",
      "['The', 'percentage', 'of', 'lung', 'cancer', 'deaths', 'among', 'the', 'workers', 'at', 'the', 'West', 'Groton', ',', 'Mass', '.,', 'paper', 'factory', 'appears', 'to', 'be', 'the', 'highest', 'for', 'any', 'asbestos', 'workers', 'studied', 'in', 'Western', 'industrialized', 'countries', ',', 'he', 'said', '.']\n",
      "['The', 'plant', ',', 'which', 'is', 'owned', 'by', 'Hollingsworth', '&', 'Vose', 'Co', '.,', 'was', 'under', 'contract', 'with', 'Lorillard', 'to', 'make', 'the', 'cigarette', 'filters', '.']\n",
      "['The', 'finding', 'probably', 'will', 'support', 'those', 'who', 'argue', 'that', 'the', 'U', '.', 'S', '.', 'should', 'regulate', 'the', 'class', 'of', 'asbestos', 'including', 'crocidolite', 'more', 'stringently', 'than', 'the', 'common', 'kind', 'of', 'asbestos', ',', 'chrysotile', ',', 'found', 'in', 'most', 'schools', 'and', 'other', 'buildings', ',', 'Dr', '.', 'Talcott', 'said', '.']\n",
      "['The', 'U', '.', 'S', '.', 'is', 'one', 'of', 'the', 'few', 'industrialized', 'nations', 'that', 'doesn', \"'\", 't', 'have', 'a', 'higher', 'standard', 'of', 'regulation', 'for', 'the', 'smooth', ',', 'needle', '-', 'like', 'fibers', 'such', 'as', 'crocidolite', 'that', 'are', 'classified', 'as', 'amphobiles', ',', 'according', 'to', 'Brooke', 'T', '.', 'Mossman', ',', 'a', 'professor', 'of', 'pathlogy', 'at', 'the', 'University', 'of', 'Vermont', 'College', 'of', 'Medicine', '.']\n",
      "['More', 'common', 'chrysotile', 'fibers', 'are', 'curly', 'and', 'are', 'more', 'easily', 'rejected', 'by', 'the', 'body', ',', 'Dr', '.', 'Mossman', 'explained', '.']\n",
      "['In', 'July', ',', 'the', 'Environmental', 'Protection', 'Agency', 'imposed', 'a', 'gradual', 'ban', 'on', 'virtually', 'all', 'uses', 'of', 'asbestos', '.']\n",
      "['By', '1997', ',', 'almost', 'all', 'remaining', 'uses', 'of', 'cancer', '-', 'causing', 'asbestos', 'will', 'be', 'outlawed', '.']\n",
      "['About', '160', 'workers', 'at', 'a', 'factory', 'that', 'made', 'paper', 'for', 'the', 'Kent', 'filters', 'were', 'exposed', 'to', 'asbestos', 'in', 'the', '1950s', '.']\n",
      "['Areas', 'of', 'the', 'factory', 'were', 'particularly', 'dusty', 'where', 'the', 'crocidolite', 'was', 'used', '.']\n",
      "['Workers', 'dumped', 'large', 'burlap', 'sacks', 'of', 'the', 'imported', 'material', 'into', 'a', 'huge', 'bin', ',', 'poured', 'in', 'cotton', 'and', 'acetate', 'fibers', 'and', 'mechanically', 'mixed', 'the', 'dry', 'fibers', 'in', 'a', 'process', 'used', 'to', 'make', 'filters', '.']\n",
      "['Workers', 'described', '\"', 'clouds', 'of', 'blue', 'dust', '\"', 'that', 'hung', 'over', 'parts', 'of', 'the', 'factory', ',', 'even', 'though', 'exhaust', 'fans', 'ventilated', 'the', 'area', '.', '\"', 'There', \"'\", 's', 'no', 'question', 'that', 'some', 'of', 'those', 'workers', 'and', 'managers', 'contracted', 'asbestos', '-', 'related', 'diseases', ',\"', 'said', 'Darrell', 'Phillips', ',', 'vice', 'president', 'of', 'human', 'resources', 'for', 'Hollingsworth', '&', 'Vose', '.', '\"', 'But', 'you', 'have', 'to', 'recognize', 'that', 'these', 'events', 'took', 'place', '35', 'years', 'ago', '.']\n",
      "['It', 'has', 'no', 'bearing', 'on', 'our', 'work', 'force', 'today', '.\"', '.', 'START', 'Yields', 'on', 'money', '-', 'market', 'mutual', 'funds', 'continued', 'to', 'slide', ',', 'amid', 'signs', 'that', 'portfolio', 'managers', 'expect', 'further', 'declines', 'in', 'interest', 'rates', '.']\n",
      "['The', 'average', 'seven', '-', 'day', 'compound', 'yield', 'of', 'the', '400', 'taxable', 'funds', 'tracked', 'by', 'IBC', '/', 'Donoghue', \"'\", 's', 'Money', 'Fund', 'Report', 'eased', 'a', 'fraction', 'of', 'a', 'percentage', 'point', 'to', '8', '.', '45', '%', 'from', '8', '.', '47', '%', 'for', 'the', 'week', 'ended', 'Tuesday', '.']\n",
      "['Compound', 'yields', 'assume', 'reinvestment', 'of', 'dividends', 'and', 'that', 'the', 'current', 'yield', 'continues', 'for', 'a', 'year', '.']\n",
      "['Average', 'maturity', 'of', 'the', 'funds', \"'\", 'investments', 'lengthened', 'by', 'a', 'day', 'to', '41', 'days', ',', 'the', 'longest', 'since', 'early', 'August', ',', 'according', 'to', 'Donoghue', \"'\", 's', '.', 'Longer', 'maturities', 'are', 'thought', 'to', 'indicate', 'declining', 'interest', 'rates', 'because', 'they', 'permit', 'portfolio', 'managers', 'to', 'retain', 'relatively', 'higher', 'rates', 'for', 'a', 'longer', 'period', '.']\n",
      "['Shorter', 'maturities', 'are', 'considered', 'a', 'sign', 'of', 'rising', 'rates', 'because', 'portfolio', 'managers', 'can', 'capture', 'higher', 'rates', 'sooner', '.']\n",
      "['The', 'average', 'maturity', 'for', 'funds', 'open', 'only', 'to', 'institutions', ',', 'considered', 'by', 'some', 'to', 'be', 'a', 'stronger', 'indicator', 'because', 'those', 'managers', 'watch', 'the']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(tokens))\n",
    "tokens[:50]\n",
    "tinytokens = tokens[:1000]\n",
    "\n",
    "for s in segment_sentences(tinytokens):\n",
    "    print (s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pierre Vinken, 61 years old, will join the board as a nonexecutive director Nov. 29.',\n",
       " 'Mr. Vinken is chairman of Elsevier N.V., the Dutch publishing group.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare to NLKT default sentence tokenizer, which works on raw text instead of tokens\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "rawtext = 'Pierre Vinken, 61 years old, will join the board as a nonexecutive director Nov. 29.  Mr. Vinken is chairman of Elsevier N.V., the Dutch publishing group.'\n",
    "sents = nltk.sent_tokenize(rawtext)\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
